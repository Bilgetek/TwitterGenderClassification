{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download()\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re # Regular Expression\n",
    "\n",
    "from sklearn.metrics import accuracy_score # to calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"gender-classifier-DFE-791531.csv\", encoding=\"latin1\")\n",
    "\n",
    "data = pd.concat([data.gender, data.description], axis=1) # we only select gender and decription(tweet) columns\n",
    "data.dropna(axis = 0, inplace = True) # to dropped the null rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>i sing my own rhythm.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>I'm the author of novels filled with family dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>louis whining and squealing and all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>Mobile guy.  49ers, Shazam, Google, Kleiner Pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female</td>\n",
       "      <td>Ricky Wilson The Best FRONTMAN/Kaiser Chiefs T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>female</td>\n",
       "      <td>you don't know me.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>brand</td>\n",
       "      <td>A global marketplace for images, videos and mu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender                                        description\n",
       "0    male                              i sing my own rhythm.\n",
       "1    male  I'm the author of novels filled with family dr...\n",
       "2    male                louis whining and squealing and all\n",
       "3    male  Mobile guy.  49ers, Shazam, Google, Kleiner Pe...\n",
       "4  female  Ricky Wilson The Best FRONTMAN/Kaiser Chiefs T...\n",
       "5  female                                 you don't know me.\n",
       "6   brand  A global marketplace for images, videos and mu..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total female tweets :  5725\n",
      "Total brand tweets  :  4328\n",
      "Total male tweets   :  5469\n"
     ]
    }
   ],
   "source": [
    "get_female = data[\"gender\"] == \"female\" # to select specific gender\n",
    "get_male = data[\"gender\"] == \"male\"\n",
    "get_brand = data[\"gender\"] == \"brand\"\n",
    "\n",
    "female_rows = data[get_female]\n",
    "male_rows = data[get_male]\n",
    "brand_rows = data[get_brand]\n",
    "\n",
    "print(\"Total female tweets : \", female_rows.count().gender) # to see counts of genders\n",
    "print(\"Total brand tweets  : \", brand_rows.count().gender)\n",
    "print(\"Total male tweets   : \", male_rows.count().gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.py:5303: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "female_rows.gender = 0\n",
    "male_rows.gender = 1\n",
    "brand_rows.gender = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frames = [female_rows, male_rows, brand_rows] list'den frame e gecis\n",
    "data = pd.concat([female_rows, male_rows, brand_rows], ignore_index=False) #to concatanate the gender rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Ricky Wilson The Best FRONTMAN/Kaiser Chiefs T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>you don't know me.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>Pll Fan // Crazy about MCD // Ramen is bae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>Renaissance art historian, University of Notti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>Senior '16 . XI-XII-MMXIV.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20030</th>\n",
       "      <td>2</td>\n",
       "      <td>Crowdsourcing #Innovation! The FINND connects ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20034</th>\n",
       "      <td>2</td>\n",
       "      <td>Where Raleigh's dynamic leaders come to connec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20038</th>\n",
       "      <td>2</td>\n",
       "      <td>The FUN site for Animal Lovers - Get the lates...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20041</th>\n",
       "      <td>2</td>\n",
       "      <td>When families go through divorce, it's helpful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20042</th>\n",
       "      <td>2</td>\n",
       "      <td>Reviews of delectable #food, picturesque #trav...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15522 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gender                                        description\n",
       "4           0  Ricky Wilson The Best FRONTMAN/Kaiser Chiefs T...\n",
       "5           0                                 you don't know me.\n",
       "8           0         Pll Fan // Crazy about MCD // Ramen is bae\n",
       "9           0  Renaissance art historian, University of Notti...\n",
       "12          0                         Senior '16 . XI-XII-MMXIV.\n",
       "...       ...                                                ...\n",
       "20030       2  Crowdsourcing #Innovation! The FINND connects ...\n",
       "20034       2  Where Raleigh's dynamic leaders come to connec...\n",
       "20038       2  The FUN site for Animal Lovers - Get the lates...\n",
       "20041       2  When families go through divorce, it's helpful...\n",
       "20042       2  Reviews of delectable #food, picturesque #trav...\n",
       "\n",
       "[15522 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "description_list = []\n",
    "for description in data.description:\n",
    "    description = re.sub(\"[^a-zA-Z]\", \" \", description)\n",
    "    # sub method finds the given pattern ([^a-zA-Z] means, NOT letter like \":\") and changes them with \" \" (space)\n",
    "    description = description.lower()\n",
    "    # we need to have all letters lowercase (because A is not equall to a)\n",
    "    description = nltk.word_tokenize(description)\n",
    "    \n",
    "    description = [word for word in description if not word in set(stopwords.words(\"english\"))] # we make a word list from our text\n",
    "    \n",
    "    lemma = nltk.WordNetLemmatizer()\n",
    "    description = [lemma.lemmatize(word) for word in description] # to find the roots of each words with lemma\n",
    "    \n",
    "    description = \" \".join(description) # to combine the words back together \n",
    "    description_list.append(description) # to add our texts to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original version:  Beauty begins the moment you decide to be yourself - Coco Chanel ëÒë_ëÕ\n",
      "New version:       beauty begin moment decide coco chanel\n"
     ]
    }
   ],
   "source": [
    "print(\"Original version: \", data.description.iloc[3982]) # here, we check if our stopwords function works\n",
    "print(\"New version:      \", description_list[3982])  # as we see, new version is cleared of stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top used 1000 words: ['account', 'action', 'activist', 'actor', 'actress', 'add', 'addict', 'addicted', 'adult', 'adventure', 'advertising', 'advice', 'advisor', 'advocate', 'affair', 'affiliate', 'aficionado', 'african', 'age', 'agency', 'air', 'aka', 'alive', 'alternative', 'alum', 'alumnus', 'amateur', 'amazing', 'amazon', 'ambassador', 'america', 'american', 'analysis', 'analyst', 'android', 'angel', 'animal', 'anime', 'answer', 'anti', 'app', 'apple', 'area', 'arsenal', 'art', 'artist', 'ask', 'aspiring', 'assistant', 'associate', 'association', 'atheist', 'athlete', 'athletics', 'author', 'available', 'average', 'avid', 'award', 'away', 'awesome', 'baby', 'bad', 'bae', 'ball', 'band', 'bar', 'baseball', 'based', 'basketball', 'beach', 'bear', 'beat', 'beautiful', 'beauty', 'beer', 'believe', 'believer', 'best', 'better', 'bieber', 'big', 'biggest', 'bio', 'bit', 'bitch', 'black', 'blacklivesmatter', 'blessed', 'blind', 'blog', 'blogger', 'blue', 'board', 'body', 'book', 'booking', 'born', 'bot', 'boxing', 'boy', 'brain', 'brand', 'breaking', 'bring', 'bringing', 'british', 'broken', 'brother', 'brown', 'build', 'building', 'business', 'buy', 'ca', 'cab', 'cake', 'california', 'called', 'canada', 'canadian', 'cancer', 'car', 'card', 'care', 'career', 'cat', 'cause', 'celebrity', 'center', 'ceo', 'certified', 'champion', 'change', 'channel', 'character', 'chat', 'check', 'chef', 'chelsea', 'chicago', 'chief', 'child', 'chocolate', 'choice', 'christ', 'christian', 'church', 'city', 'class', 'classic', 'click', 'client', 'cloud', 'club', 'coach', 'coast', 'coffee', 'collector', 'college', 'com', 'come', 'comedian', 'comic', 'coming', 'commercial', 'communication', 'community', 'company', 'computer', 'concert', 'connect', 'conservative', 'consultant', 'contact', 'content', 'continuous', 'contributor', 'control', 'cook', 'cool', 'country', 'county', 'course', 'cover', 'coverage', 'covering', 'craft', 'crazy', 'create', 'created', 'creating', 'creative', 'creator', 'credit', 'cricket', 'culture', 'curator', 'current', 'currently', 'customer', 'cute', 'da', 'dad', 'daddy', 'daily', 'damn', 'dan', 'dance', 'dancer', 'dark', 'data', 'date', 'daughter', 'day', 'dc', 'dead', 'deal', 'death', 'dedicated', 'deep', 'delivers', 'design', 'designer', 'developer', 'development', 'die', 'diet', 'different', 'digital', 'direction', 'director', 'discover', 'disney', 'dj', 'dm', 'dog', 'dont', 'draw', 'dream', 'dreamer', 'drink', 'dude', 'eagle', 'earth', 'east', 'easy', 'eat', 'ed', 'editor', 'education', 'el', 'email', 'employer', 'empowered', 'en', 'end', 'endorsement', 'energy', 'engineer', 'england', 'english', 'enjoy', 'entertainment', 'enthusiast', 'entrepreneur', 'er', 'especially', 'est', 'estate', 'et', 'event', 'everyday', 'ex', 'executive', 'experience', 'expert', 'expressed', 'extremely', 'eye', 'face', 'facebook', 'fact', 'fair', 'faith', 'fall', 'family', 'fan', 'fanatic', 'fangirl', 'fantasy', 'fashion', 'fast', 'father', 'favorite', 'fb', 'fc', 'fear', 'feature', 'feed', 'feel', 'female', 'feminist', 'fi', 'fiction', 'fight', 'fighting', 'film', 'finance', 'financial', 'financially', 'finding', 'fine', 'firm', 'fish', 'fitness', 'fl', 'flash', 'florida', 'flower', 'fly', 'fm', 'focus', 'follow', 'followed', 'follower', 'following', 'follows', 'food', 'foodie', 'football', 'forever', 'founder', 'freak', 'free', 'freedom', 'freelance', 'fresh', 'friend', 'friendly', 'fuck', 'fucking', 'fun', 'funny', 'future', 'game', 'gamer', 'gaming', 'gay', 'geek', 'general', 'geo', 'geography', 'getting', 'gift', 'girl', 'global', 'gmail', 'goal', 'god', 'going', 'gold', 'golf', 'gon', 'good', 'google', 'got', 'government', 'grad', 'graduate', 'graphic', 'great', 'greatest', 'green', 'grfoxfjwpv', 'group', 'grow', 'growing', 'guide', 'guitar', 'guy', 'gym', 'hair', 'half', 'hand', 'happen', 'happening', 'happiness', 'happy', 'hard', 'harry', 'hate', 'head', 'health', 'healthcare', 'healthy', 'heart', 'hell', 'hello', 'help', 'helping', 'hero', 'hey', 'hi', 'high', 'highly', 'hip', 'history', 'hit', 'hockey', 'home', 'hop', 'hope', 'host', 'hot', 'hottest', 'hour', 'house', 'houston', 'http', 'huge', 'human', 'humble', 'husband', 'idea', 'ig', 'im', 'image', 'important', 'improve', 'independent', 'indie', 'individual', 'industry', 'info', 'information', 'innovation', 'inquiry', 'inspiration', 'inspirational', 'insta', 'instagram', 'interested', 'interesting', 'international', 'internet', 'interview', 'investment', 'io', 'iphone', 'irish', 'issue', 'itunes', 'jack', 'james', 'jesus', 'job', 'john', 'join', 'joke', 'journalist', 'junior', 'junkie', 'justice', 'justin', 'kath', 'keeping', 'key', 'kid', 'kind', 'king', 'know', 'knowledge', 'known', 'la', 'lady', 'largest', 'latest', 'laugh', 'law', 'lawyer', 'le', 'lead', 'leader', 'leadership', 'leading', 'league', 'learn', 'learning', 'leave', 'left', 'legal', 'legend', 'lesson', 'let', 'level', 'liberal', 'library', 'life', 'lifestyle', 'light', 'like', 'lil', 'line', 'link', 'listen', 'little', 'live', 'liverpool', 'living', 'local', 'location', 'london', 'long', 'look', 'looking', 'lord', 'los', 'lost', 'lot', 'louis', 'love', 'loved', 'lover', 'loving', 'mad', 'magazine', 'mail', 'major', 'make', 'maker', 'makeup', 'making', 'male', 'man', 'management', 'manager', 'managing', 'manchester', 'map', 'market', 'marketer', 'marketing', 'married', 'master', 'math', 'matter', 'maybe', 'mean', 'medical', 'medium', 'meet', 'member', 'men', 'met', 'metal', 'mi', 'miami', 'michael', 'military', 'mind', 'minute', 'miss', 'mission', 'mix', 'mobile', 'model', 'modern', 'mom', 'moment', 'mon', 'monday', 'money', 'moon', 'morning', 'mother', 'movie', 'mr', 'mufc', 'mum', 'music', 'musician', 'na', 'nation', 'national', 'native', 'natural', 'nature', 'nba', 'nd', 'need', 'nerd', 'net', 'network', 'new', 'news', 'newspaper', 'nfl', 'nice', 'nigeria', 'nigga', 'night', 'non', 'north', 'nsfw', 'number', 'nurse', 'ny', 'nyc', 'obsessed', 'occasional', 'offer', 'office', 'officer', 'official', 'oh', 'ohio', 'old', 'online', 'open', 'opinion', 'opportunity', 'order', 'organization', 'original', 'outlook', 'owner', 'page', 'pain', 'paper', 'parent', 'partner', 'party', 'passion', 'passionate', 'pc', 'peace', 'people', 'perfect', 'person', 'personal', 'pet', 'phd', 'phone', 'photo', 'photographer', 'photography', 'pic', 'pick', 'picture', 'piece', 'pin', 'pizza', 'place', 'plan', 'play', 'player', 'playing', 'plus', 'pm', 'podcast', 'poet', 'policy', 'political', 'politics', 'pop', 'porn', 'positive', 'post', 'power', 'pr', 'practice', 'premier', 'president', 'press', 'pretty', 'price', 'prince', 'princess', 'private', 'pro', 'probably', 'problem', 'producer', 'product', 'production', 'prof', 'professional', 'professor', 'profile', 'profit', 'program', 'progress', 'progressive', 'project', 'promo', 'promote', 'promoting', 'promotion', 'property', 'proud', 'provide', 'provides', 'providing', 'public', 'published', 'publisher', 'purpose', 'quality', 'que', 'queen', 'question', 'quiz', 'quote', 'radio', 'raised', 'random', 'rap', 'read', 'reader', 'reading', 'ready', 'real', 'reality', 'really', 'reason', 'record', 'red', 'register', 'related', 'relationship', 'remember', 'rendezvous', 'reporter', 'research', 'resident', 'resource', 'respect', 'rest', 'restaurant', 'retired', 'retweets', 'review', 'right', 'rip', 'road', 'rock', 'romance', 'rp', 'rt', 'rts', 'rule', 'run', 'runner', 'running', 'rzoj', 'sad', 'said', 'sale', 'san', 'save', 'say', 'sc', 'school', 'sci', 'science', 'se', 'search', 'season', 'seattle', 'second', 'secret', 'secure', 'security', 'seen', 'self', 'sell', 'selling', 'send', 'senior', 'sense', 'seo', 'series', 'service', 'serving', 'set', 'sex', 'sexy', 'shall', 'share', 'sharing', 'shit', 'shop', 'shopping', 'short', 'sign', 'simple', 'singer', 'single', 'sister', 'site', 'sleep', 'small', 'smile', 'snap', 'snapchat', 'soccer', 'social', 'socialmedia', 'society', 'software', 'solution', 'son', 'song', 'songwriter', 'soon', 'sorry', 'soul', 'sound', 'source', 'south', 'southern', 'space', 'speak', 'speaker', 'special', 'specialist', 'specializing', 'spirit', 'spiritually', 'sport', 'st', 'stan', 'stand', 'star', 'start', 'started', 'startup', 'state', 'station', 'stay', 'step', 'stock', 'stop', 'store', 'story', 'straight', 'strategist', 'strategy', 'stream', 'streamer', 'street', 'strength', 'strong', 'student', 'study', 'stuff', 'style', 'subscribe', 'success', 'sun', 'super', 'support', 'supporter', 'supporting', 'sure', 'sweet', 'ta', 'taken', 'taking', 'talent', 'talk', 'talkradio', 'targeted', 'tax', 'taylor', 'tea', 'teacher', 'team', 'tech', 'technology', 'tell', 'tennis', 'texas', 'th', 'thank', 'thanks', 'theatre', 'thing', 'think', 'thinking', 'thought', 'ticket', 'time', 'tip', 'today', 'tour', 'town', 'track', 'trade', 'trainer', 'training', 'trash', 'travel', 'traveler', 'traveller', 'trend', 'true', 'trump', 'trust', 'truth', 'try', 'trying', 'turn', 'tv', 'tweet', 'tweeting', 'tweetmyjobs', 'twitch', 'twitter', 'type', 'uk', 'unique', 'united', 'universe', 'university', 'update', 'ur', 'urban', 'usa', 'use', 'using', 'ux', 'vegan', 'veteran', 'vibe', 'video', 'view', 'vintage', 'visit', 'voice', 'volunteer', 'wait', 'walk', 'walking', 'wan', 'want', 'war', 'warrior', 'washington', 'watch', 'watching', 'water', 'way', 'wear', 'weather', 'web', 'website', 'wedding', 'week', 'welcome', 'west', 'white', 'wife', 'wild', 'win', 'wine', 'winner', 'winning', 'wish', 'wolf', 'woman', 'wonderful', 'word', 'work', 'worker', 'working', 'world', 'worldwide', 'worth', 'wrestling', 'write', 'writer', 'writing', 'wrong', 'wwe', 'xx', 'ya', 'yeah', 'year', 'yes', 'yo', 'yoga', 'york', 'young', 'youth', 'youtube', 'youtuber', 'yr', 'zayn']\n"
     ]
    }
   ],
   "source": [
    "# We will implement \"bag of words\" method\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "max_features = 1000 # we can choose how many features we want to add \n",
    "cv = CountVectorizer(max_features=max_features, stop_words = \"english\")# in this method, we remove the stopwords (irrelevant words) in English language. (like \"of\", \"and\", \"the\" etc.)\n",
    "matrix = cv.fit_transform(description_list).toarray() # to create a matrix with new version texts\n",
    "\n",
    "print(\"Top used {} words: {}\".format(max_features, cv.get_feature_names())) # we can check here the top used words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.iloc[:, 0].values # we only select the gender column\n",
    "x = matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42) #we split test size 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracy(y_test, y_pred): # instead of code reputation this function provides to find accuracy score\n",
    "    return 100.0 * accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model accuracy(%): 58.71\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Implementation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# training\n",
    "RandomForest = RandomForestClassifier()\n",
    "RandomForest.fit(x_train, y_train)\n",
    "\n",
    "# prediction\n",
    "y_pred = RandomForest.predict(x_test)\n",
    "\n",
    "print('%s: %.2f' % ('Random Forest Model accuracy(%)', getAccuracy(y_test, y_pred))) # calling getAccuracy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes accuracy(%): 56.88\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes Implementation\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# training\n",
    "GaussianNaiveBayes = GaussianNB()\n",
    "GaussianNaiveBayes.fit(x_train, y_train)\n",
    "\n",
    "# prediction\n",
    "y_pred = GaussianNaiveBayes.predict(x_test)\n",
    "\n",
    "print('%s: %.2f' % ('Gaussian Naive Bayes accuracy(%)', getAccuracy(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree accuracy(%): 53.17\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Classifier Implementation\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# training\n",
    "DecisionTree = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "DecisionTree.fit(x_train, y_train)\n",
    "\n",
    "# prediction\n",
    "y_pred = DecisionTree.predict(x_test)\n",
    "\n",
    "print('%s: %.2f' % ('Decision Tree accuracy(%)', getAccuracy(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold # Provides train/test indices to split data in train/test sets.\n",
    "\n",
    "GaussianNaiveBayes = GaussianNB()\n",
    "kfold = StratifiedKFold(n_splits=10, random_state=42, shuffle=True)\n",
    "cv_results = cross_val_score(GaussianNaiveBayes, x_train, y_train, cv=kfold, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes accuracy(%): 55.85\n"
     ]
    }
   ],
   "source": [
    "print('%s: %.2f' % ('Gaussian Naive Bayes accuracy(%)', cv_results.mean() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test,y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.heatmap(cm,cbar=False,annot=True,cmap=\"Blues\",fmt=\"d\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
